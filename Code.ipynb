{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf27a4d-3a45-44aa-8b8b-829e789af437",
   "metadata": {},
   "source": [
    "Background\n",
    "Cirrhosis results from prolonged liver damage, leading to extensive scarring, often due to\n",
    "conditions like hepatitis or chronic alcohol consumption. The data provided is a subset sourced\n",
    "from a Mayo Clinic study on primary biliary cirrhosis (PBC) of the liver carried out from 1974\n",
    "to 1984.\n",
    "This is a dataset to develop and validate machine learning algorithms for predicting the survival\n",
    "status of the collected patients. There are 312 patients in the data set (224 for train and 88 for\n",
    "test), and each patient has 17 collected features. The aim of this task is to utilize 17 clinical\n",
    "features for predicting survival state of patients with liver cirrhosis. The survival states include\n",
    "0 = D (death), 1 = C (censored), 2 = CL (censored due to liver transplantation)\n",
    "Specifically, the problem you are going to solve is: Can you\n",
    "• Accurately predict the survival status given the labelled data?\n",
    "• Well explain your prediction and the associated findings? For example, identify the key\n",
    "factors which are strongly associated with the response variable, i.e., survival status.\n",
    "\n",
    "Data set\n",
    "The training data contains 224 rows and the test data contains 88 rows, each of which have 19\n",
    "columns (excluding the ID column): the N_Days attribute is the number of days between\n",
    "registration and the earlier of death, transplantation, or study analysis time in July 1986, the\n",
    "status attribute is the target variable that we will predict, and the rest 17 columns can be used\n",
    "as the input features. The details of the original data set can be found and downloaded in the\n",
    "original UCI repository. The values of the “status” column in the test set is leaved with empty\n",
    "to simulate real world predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb652f-6f8a-4168-aae8-4c97064ff2aa",
   "metadata": {},
   "source": [
    "1. Load and explore the training and test dataset, do necessary pre-processing.\n",
    "a. Show both training and test dataset size.\n",
    "b. Based on the training and test data, show the feature types, and indicate which\n",
    "feature has missing values.\n",
    "c. Use an appropriate method to deal with the missing values for both the training\n",
    "and test set.\n",
    "d. Do necessary encoding for the categorical features.\n",
    "e. Show the label distribution based on the training data, is it a balanced training\n",
    "set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35202b9-d240-465c-a9d4-9c529ab6bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.A\n",
      "Training data size: (224, 20)\n",
      "Test data size: (88, 20)\n",
      "\n",
      "1.B\n",
      "Training data feature types:\n",
      "trainID            int64\n",
      "N_Days             int64\n",
      "Status            object\n",
      "Drug              object\n",
      "Age                int64\n",
      "Sex               object\n",
      "Ascites           object\n",
      "Hepatomegaly      object\n",
      "Spiders           object\n",
      "Edema             object\n",
      "Bilirubin        float64\n",
      "Cholesterol      float64\n",
      "Albumin          float64\n",
      "Copper           float64\n",
      "Alk_Phos         float64\n",
      "SGOT             float64\n",
      "Tryglicerides    float64\n",
      "Platelets        float64\n",
      "Prothrombin      float64\n",
      "Stage              int64\n",
      "dtype: object\n",
      "\n",
      "Training data missing values:\n",
      "Cholesterol      23\n",
      "Copper            2\n",
      "Tryglicerides    24\n",
      "Platelets         3\n",
      "dtype: int64\n",
      "\n",
      "Test data feature types:\n",
      "testID             int64\n",
      "N_Days             int64\n",
      "Status           float64\n",
      "Drug              object\n",
      "Age                int64\n",
      "Sex               object\n",
      "Ascites           object\n",
      "Hepatomegaly      object\n",
      "Spiders           object\n",
      "Edema             object\n",
      "Bilirubin        float64\n",
      "Cholesterol      float64\n",
      "Albumin          float64\n",
      "Copper             int64\n",
      "Alk_Phos         float64\n",
      "SGOT             float64\n",
      "Tryglicerides    float64\n",
      "Platelets        float64\n",
      "Prothrombin      float64\n",
      "Stage              int64\n",
      "dtype: object\n",
      "\n",
      "Test data missing values:\n",
      "Status           88\n",
      "Cholesterol       5\n",
      "Tryglicerides     6\n",
      "Platelets         1\n",
      "dtype: int64\n",
      "\n",
      "1.C\n",
      "Missing values after imputation:\n",
      "Training set: 0\n",
      "Test set: 0\n",
      "\n",
      "1.D\n",
      "Categorical features encoded using Label Encoding\n",
      "\n",
      "1.E\n",
      "Label distribution in the training set:\n",
      "Status\n",
      "C     0.531250\n",
      "D     0.415179\n",
      "CL    0.053571\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv(\"cirrhosis_train.csv\")\n",
    "test_data = pd.read_csv(\"cirrhosis_test.csv\")\n",
    "\n",
    "# 1.A\n",
    "print(\"1.A\")\n",
    "print(\"Training data size:\", train_data.shape)\n",
    "print(\"Test data size:\", test_data.shape)\n",
    "print()\n",
    "\n",
    "# 1.B\n",
    "print(\"1.B\")\n",
    "print(\"Training data feature types:\")\n",
    "print(train_data.dtypes)\n",
    "print(\"\\nTraining data missing values:\")\n",
    "print(train_data.isnull().sum()[train_data.isnull().sum() > 0])\n",
    "print(\"\\nTest data feature types:\")\n",
    "print(test_data.dtypes)\n",
    "print(\"\\nTest data missing values:\")\n",
    "print(test_data.isnull().sum()[test_data.isnull().sum() > 0])\n",
    "print()\n",
    "\n",
    "# 1.C\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define separate imputers for numerical and categorical features\n",
    "imputer_numerical = SimpleImputer(strategy=\"mean\")\n",
    "imputer_categorical = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Separate the features by data type for the training set, excluding \"trainID\" and \"Status\" columns\n",
    "train_features = train_data.drop([\"trainID\", \"Status\"], axis=1)\n",
    "train_numerical_features = train_features.select_dtypes(include=np.number)\n",
    "train_categorical_features = train_features.select_dtypes(include=object)\n",
    "\n",
    "# Impute numerical features in the training set\n",
    "imputer_numerical.fit(train_numerical_features)\n",
    "train_numerical_features = pd.DataFrame(imputer_numerical.transform(train_numerical_features), columns=train_numerical_features.columns)\n",
    "\n",
    "# Impute categorical features in the training set\n",
    "imputer_categorical.fit(train_categorical_features)\n",
    "train_categorical_features = pd.DataFrame(imputer_categorical.transform(train_categorical_features), columns=train_categorical_features.columns)\n",
    "\n",
    "# Combine imputed features back into the DataFrame for the training set, including \"trainID\" and \"Status\" columns\n",
    "train_df = pd.concat([train_data[[\"trainID\", \"Status\"]], train_numerical_features, train_categorical_features], axis=1)\n",
    "\n",
    "# Separate the features by data type for the test set, excluding \"testID\" and \"Status\" columns\n",
    "test_features = test_data.drop([\"testID\", \"Status\"], axis=1)\n",
    "test_numerical_features = test_features.select_dtypes(include=np.number)\n",
    "test_categorical_features = test_features.select_dtypes(include=object)\n",
    "\n",
    "# Impute numerical features in the test set\n",
    "test_numerical_features = pd.DataFrame(imputer_numerical.transform(test_numerical_features), columns=test_numerical_features.columns)\n",
    "\n",
    "# Impute categorical features in the test set\n",
    "test_categorical_features = pd.DataFrame(imputer_categorical.transform(test_categorical_features), columns=test_categorical_features.columns)\n",
    "\n",
    "# Combine imputed features back into the DataFrame for the test set, including \"testID\" column\n",
    "test_df = pd.concat([test_data[\"testID\"], test_numerical_features, test_categorical_features], axis=1)\n",
    "\n",
    "print(\"1.C\")\n",
    "print(\"Missing values after imputation:\")\n",
    "print(\"Training set:\", train_df.isnull().sum().sum())\n",
    "print(\"Test set:\", test_df.isnull().sum().sum())\n",
    "print()\n",
    "\n",
    "# 1.D Encoding categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\"]\n",
    "\n",
    "# Create a LabelEncoder object for each categorical column\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Fit the label encoders on the combined data (train + test)\n",
    "for column in categorical_columns:\n",
    "    combined_data = pd.concat([train_df[column], test_df[column]])\n",
    "    label_encoders[column].fit(combined_data)\n",
    "\n",
    "# Encode categorical features in the training set\n",
    "for column in categorical_columns:\n",
    "    train_df[column] = label_encoders[column].transform(train_df[column])\n",
    "\n",
    "# Encode categorical features in the test set\n",
    "for column in categorical_columns:\n",
    "    test_df[column] = label_encoders[column].transform(test_df[column])\n",
    "\n",
    "print(\"1.D\")\n",
    "print(\"Categorical features encoded using Label Encoding\")\n",
    "print()\n",
    "\n",
    "# 1.E Label distribution in the training set\n",
    "print(\"1.E\")\n",
    "print(\"Label distribution in the training set:\")\n",
    "label_counts = train_df[\"Status\"].value_counts(normalize=True)\n",
    "print(label_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(label_counts.index, label_counts.values)\n",
    "plt.xlabel(\"Status\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Label Distribution in the Training Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59354b33-6964-4064-862e-0bbf65017c08",
   "metadata": {},
   "source": [
    "2. Based on the pre-processed training data from question 1, create three supervised machine learning (ML) models for predicting “Status”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27989ccb-d616-4034-b9e4-617ba71fbe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8\n",
      "Recall: 0.8\n",
      "F1-score: 0.8\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.8444444444444444\n",
      "Precision: 0.8503831417624522\n",
      "Recall: 0.8444444444444444\n",
      "F1-score: 0.8336541889483067\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.8222222222222222\n",
      "Precision: 0.8262371615312792\n",
      "Recall: 0.8222222222222222\n",
      "F1-score: 0.8121810699588476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Create three supervised ML models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = train_df.drop([\"trainID\", \"Status\"], axis=1)\n",
    "y = train_df[\"Status\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Create and train the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd1b9e-92bc-46f5-8a97-eebe6e1e2fea",
   "metadata": {},
   "source": [
    "2. A. Use an appropriate validation method, report performance score using a suitable metric. Is it possible that the presented result is an underfitted or overfitted one? Justify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3de85e-7a8d-4b56-8ff1-74c86a1689fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Cross-validation scores: [0.73333333 0.77777778 0.68888889 0.75555556 0.75      ]\n",
      "Mean cross-validation score: 0.7411111111111112\n",
      "Training score: 0.8125\n",
      "The model seems to be well-fitted.\n",
      "\n",
      "Random Forest:\n",
      "Cross-validation scores: [0.8        0.8        0.68888889 0.68888889 0.79545455]\n",
      "Mean cross-validation score: 0.7546464646464647\n",
      "Training score: 1.0\n",
      "The model may be overfitting.\n",
      "\n",
      "SVM:\n",
      "Cross-validation scores: [0.82222222 0.84444444 0.68888889 0.73333333 0.77272727]\n",
      "Mean cross-validation score: 0.7723232323232322\n",
      "Training score: 0.8571428571428571\n",
      "The model seems to be well-fitted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = train_df.drop([\"trainID\", \"Status\"], axis=1)\n",
    "y = train_df[\"Status\"]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# 2.a. Use k-fold cross-validation and assess underfitting/overfitting\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(accuracy_score)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 5\n",
    "for model_name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=k, scoring=scoring)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "    \n",
    "    # Assess underfitting/overfitting\n",
    "    model.fit(X_scaled, y)\n",
    "    train_score = model.score(X_scaled, y)\n",
    "    print(\"Training score:\", train_score)\n",
    "    \n",
    "    if abs(train_score - cv_scores.mean()) > 0.1:\n",
    "        if train_score > cv_scores.mean():\n",
    "            print(\"The model may be overfitting.\")\n",
    "        else:\n",
    "            print(\"The model may be underfitting.\")\n",
    "    else:\n",
    "        print(\"The model seems to be well-fitted.\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46ef98-cc6f-4296-923a-3fcd094023e6",
   "metadata": {},
   "source": [
    "    Based on the cross-validation results, the Logistic Regression and SVM models appear to be well-fitted, while the Random Forest model shows signs of overfitting. The Logistic Regression and SVM models have training scores that are slightly higher than their mean cross-validation scores, but the differences are within an acceptable threshold (0.1). This indicates that these models strike a good balance between fitting the training data and generalizing to unseen data. They are less likely to be underfitted or overfitted.\n",
    "\n",
    "    On the other hand, the Random Forest model has a training score of 1.0, which is significantly higher than its mean cross-validation score of 0.7546. This large difference (greater than the threshold of 0.1) suggests that the Random Forest model is likely overfitting. It performs perfectly on the training data but fails to generalize well to unseen data. Overfitting occurs when a model learns the noise and specific patterns in the training data too closely, leading to poor performance on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd40b5-dd31-499a-9f01-aa117e59dfc2",
   "metadata": {},
   "source": [
    "3. Use the best model that you get from question 2, do prediction on the pre-processed test set. Save your prediction (the prediction should contain two columns only: testID and Status), and submit it to the specific Kaggle in-class platform, do a screenshot of your model performance and report it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e376014f-e075-4326-ad40-6fc5c1041c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the SVM model is the best model based on the results from question 2\n",
    "\n",
    "# Fit the SVM model on the entire scaled training data\n",
    "best_model = SVC(random_state=42)\n",
    "best_model.fit(X_scaled, y)\n",
    "\n",
    "# Make predictions on the pre-processed test set\n",
    "test_features = test_df.drop([\"testID\"], axis=1)\n",
    "test_scaled = scaler.transform(test_features)\n",
    "test_predictions = best_model.predict(test_scaled)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "submission_df = pd.DataFrame({'testID': test_df['testID'], 'Status': test_predictions})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12faaec4-e1f9-429c-a70e-aec94e2d2358",
   "metadata": {},
   "source": [
    "4. Analyse the importance of the features for predicting “Status” using two different approaches. Give statistical reasons of your findings.\n",
    "\n",
    "To figure out which features are most important for predicting the \"Status\" variable, we can use two methods:\n",
    "\n",
    "Correlation analysis:\n",
    "\n",
    "    - This method looks at how strongly each feature is related to the \"Status\" variable.\n",
    "    - We calculate correlation coefficients, which range from -1 to +1.\n",
    "    - A positive value means that as the feature value goes up, the chance of a specific status goes up.\n",
    "    - A negative value means that as the feature value goes up, the chance of a specific status goes down.\n",
    "    - We can do statistical tests to see if the correlations are significant or just due to chance.\n",
    "    - Features with stronger correlations and statistically significant results are considered more important.\n",
    "\n",
    "Feature importance from machine learning models:\n",
    "\n",
    "    - Some machine learning models, like Random Forest or Gradient Boosting, can tell us how much each feature contributes to the predictions.\n",
    "    - We train the model on the data and get feature importance scores.\n",
    "    - Features with higher scores are more important for predicting the \"Status\" variable.\n",
    "    - We can compare the results from different models to get a better idea of which features are consistently important.\n",
    "    - These models consider how features work together to make predictions.\n",
    "\n",
    "    It's important to think about both statistical significance (is the result just due to chance?) and practical significance (does the result actually matter in the real world?). We should also use our knowledge of the problem to make sense of the results.\n",
    "\n",
    "    By using both correlation analysis and feature importance from machine learning models, we can get a good understanding of which features are most helpful for predicting the \"Status\" variable. This can help us choose the best features, understand the model better, and make good decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
